{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/near129/othello/blob/feature%2Ffix_alphazero/pytorch_and_onnx_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l80JdcR-BFlY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATaBkxd8BIcJ"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.height = self.width = 8\n",
        "        self.ouput_size = 8 * 8\n",
        "        self.dropout_late = 0.5\n",
        "        in_channels = 2\n",
        "        channels = 64\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "            nn.Conv2d(channels, channels, 3),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "            nn.Conv2d(channels, channels, 3),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "        )\n",
        "\n",
        "        self.fc_input = channels * (self.width - 4) * (self.height - 4)\n",
        "        self.dropout = nn.Dropout(self.dropout_late, inplace=True)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(self.fc_input, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            self.relu,\n",
        "            self.dropout,\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            self.relu,\n",
        "            self.dropout,\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = x.view(-1, self.fc_input)\n",
        "        x = self.layer2(x)\n",
        "        policy = self.fc3(x)\n",
        "        value = self.fc4(x)\n",
        "        return self.softmax(policy), self.tanh(value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97uNCR6qBsbR",
        "outputId": "e238dfbf-c617-4a82-d20c-c201e8ed2cd3"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime onnx timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "GbCCpJtvG2Du",
        "outputId": "a3b2f4a3-05e5-4c0d-ae5b-fac62454e96e"
      },
      "outputs": [],
      "source": [
        "model_i8 = torch.quantization.quantize_dynamic(Model())\n",
        "dummy_input = torch.randn(1, 2, 8, 8)\n",
        "_ = model_i8(dummy_input)\n",
        "torch.onnx.export(model_i8 , dummy_input, 'model_test.onnx', opset_version=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMc6koPsGDbm",
        "outputId": "9255469d-0282-4806-aebe-0a2331a69177"
      },
      "outputs": [],
      "source": [
        "!pip install onnxoptimizer onnx-simplifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "5Lln_dfQBRPh",
        "outputId": "08345296-760a-4e52-cdb2-fed2b3eb2190"
      },
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(1, 2, 8, 8)\n",
        "torch.onnx.export(Model(), dummy_input, 'model.onnx', opset_version=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3vyE4ULC8t2"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "E0EvRu0mCXjq",
        "outputId": "fb63ac7e-6f6e-4a75-87bf-d5e7d165b13b"
      },
      "outputs": [],
      "source": [
        "model = onnx.load('model.onnx')\n",
        "modeli8 = onnx.load('modeli8.onnx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32fzu7xyDEuE"
      },
      "outputs": [],
      "source": [
        "onnx.checker.check_model(model)\n",
        "onnx.checker.check_model(modeli8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDOvrBsRDMkk"
      },
      "outputs": [],
      "source": [
        "ort_session = onnxruntime.InferenceSession('model.onnx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8MKb2JyDa4O"
      },
      "outputs": [],
      "source": [
        "ort_sessioni8 = onnxruntime.InferenceSession('modeli8.onnx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHP3VugoI_4H"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "class EfficientNet(torch.nn.Module):\n",
        "    def __init__(self, backbone='mixnet_s', features=256, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.dropout = dropout\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone, num_classes=self.features, in_chans=2, exportable=True\n",
        "        )\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(self.features)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(self.dropout, inplace=True)\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.dropout(self.relu(self.bn(x)))\n",
        "        policy = self.fc3(x)\n",
        "        value = self.fc4(x)\n",
        "        return self.softmax(policy), self.tanh(value)\n",
        "        \n",
        "dummy_input = torch.randn(1, 2, 8, 8)\n",
        "_ = EfficientNet().eval()(dummy_input)\n",
        "torch.onnx.export(Model(), dummy_input, 'efficientnet.onnx', opset_version=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-uUr2FWT4hQ",
        "outputId": "d81706fa-f2af-40cc-f063-0242273f0bdc"
      },
      "outputs": [],
      "source": [
        "model = Model().eval()\n",
        "model_i8 = torch.quantization.quantize_dynamic(model).eval()\n",
        "dummy_input = [torch.randn(1, 2, 8, 8) for _ in range(500)]\n",
        "%time _=[model(x) for x in dummy_input]\n",
        "%time _=[model_i8(x) for x in dummy_input]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jrpwnPTCTL1"
      },
      "outputs": [],
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType, quantize_qat\n",
        "model_input = \"efficientnet.onnx\"\n",
        "model_output = \"efficientnet_i8.onnx\"\n",
        "quantize_dynamic(model_input, model_output, weight_type=QuantType.QUInt8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jegxh6iSRD-C",
        "outputId": "37bdfccc-71f8-40b7-806c-38ff31da22ca"
      },
      "outputs": [],
      "source": [
        "!python -m onnxsim efficientnet.onnx efficientnet_opt.onnx\n",
        "!python -m onnxsim efficientnet_i8.onnx efficientnet_i8_opt.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-aEWUR0N8Xu"
      },
      "outputs": [],
      "source": [
        "model_input = \"efficientnet_opt.onnx\"\n",
        "model_output = \"efficientnet_opt_i8.onnx\"\n",
        "quantize_dynamic(model_input, model_output, weight_type=QuantType.QUInt8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ZBirupFkIs",
        "outputId": "6e1b2e1a-be2a-40c8-e018-163893c331a6"
      },
      "outputs": [],
      "source": [
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUhv-wBOKOhR",
        "outputId": "d7733a5a-774b-49c8-dce7-a5a7b2defbc2"
      },
      "outputs": [],
      "source": [
        "ort_session = onnxruntime.InferenceSession('efficientnet.onnx')\n",
        "ort_session_opt = onnxruntime.InferenceSession('efficientnet_opt.onnx')\n",
        "ort_session_i8 = onnxruntime.InferenceSession('efficientnet_i8.onnx')\n",
        "# ort_session_opt_i = onnxruntime.InferenceSession('efficientnet_opt_i8.onnx')\n",
        "ort_session_i8_opt = onnxruntime.InferenceSession('efficientnet_i8_opt.onnx')\n",
        "dummy_input = [torch.randn(1, 2, 8, 8).numpy().astype(np.float32) for _ in range(500)]\n",
        "%time _=[ort_session.run(None, {'input.1': x}) for x in dummy_input]\n",
        "%time _=[ort_session_opt.run(None, {'input.1': x}) for x in dummy_input]\n",
        "%time _=[ort_session_i8.run(None, {'input.1': x}) for x in dummy_input]\n",
        "# %time _=[ort_session_opt_i8.run(None, {'input.1': x}) for x in dummy_input]\n",
        "%time _=[ort_session_i8_opt.run(None, {'input.1': x}) for x in dummy_input]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90OTolgZKxQ4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOlgLbSLJ1ZrmdESEvwco1E",
      "include_colab_link": true,
      "name": "pytorch_and_onnx_quantization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
