{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_and_onnx_quantization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlgLbSLJ1ZrmdESEvwco1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/near129/othello/blob/feature%2Ffix_alphazero/pytorch_and_onnx_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l80JdcR-BFlY"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATaBkxd8BIcJ"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.height = self.width = 8\n",
        "        self.ouput_size = 8 * 8\n",
        "        self.dropout_late = 0.5\n",
        "        in_channels = 2\n",
        "        channels = 64\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "            nn.Conv2d(channels, channels, 3),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "            nn.Conv2d(channels, channels, 3),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            self.relu,\n",
        "        )\n",
        "\n",
        "        self.fc_input = channels * (self.width - 4) * (self.height - 4)\n",
        "        self.dropout = nn.Dropout(self.dropout_late, inplace=True)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(self.fc_input, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            self.relu,\n",
        "            self.dropout,\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            self.relu,\n",
        "            self.dropout,\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = x.view(-1, self.fc_input)\n",
        "        x = self.layer2(x)\n",
        "        policy = self.fc3(x)\n",
        "        value = self.fc4(x)\n",
        "        return self.softmax(policy), self.tanh(value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97uNCR6qBsbR",
        "outputId": "e238dfbf-c617-4a82-d20c-c201e8ed2cd3"
      },
      "source": [
        "!pip install onnxruntime onnx timm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.10.1)\n",
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "GbCCpJtvG2Du",
        "outputId": "a3b2f4a3-05e5-4c0d-ae5b-fac62454e96e"
      },
      "source": [
        "model_i8 = torch.quantization.quantize_dynamic(Model())\n",
        "dummy_input = torch.randn(1, 2, 8, 8)\n",
        "_ = model_i8(dummy_input)\n",
        "torch.onnx.export(model_i8 , dummy_input, 'model_test.onnx', opset_version=11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-e10150dea0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_i8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_i8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_test.onnx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    278\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                 \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     graph, params, torch_out, module = _create_jit_graph(model, args,\n\u001b[0;32m--> 459\u001b[0;31m                                                          _retain_param_name)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args, _retain_param_name)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# A basic sanity check: make sure the state_dict keys are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# before and after running the model.  Fail fast!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0morig_state_dict_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mtrace_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_unique_state_dict\u001b[0;34m(module, keep_vars)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mfiltered_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mfiltered_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'detach'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMc6koPsGDbm",
        "outputId": "9255469d-0282-4806-aebe-0a2331a69177"
      },
      "source": [
        "!pip install onnxoptimizer onnx-simplifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxoptimizer\n",
            "  Downloading onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl (466 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 466 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting onnx-simplifier\n",
            "  Downloading onnx-simplifier-0.3.6.tar.gz (13 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 183 kB/s \n",
            "\u001b[?25hCollecting onnxruntime>=1.6.0\n",
            "  Downloading onnxruntime-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.6.0->onnx-simplifier) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.6.0->onnx-simplifier) (1.12)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.7.0->onnx-simplifier) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnxoptimizer) (3.7.4.3)\n",
            "Building wheels for collected packages: onnx-simplifier\n",
            "  Building wheel for onnx-simplifier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.6-py3-none-any.whl size=12873 sha256=454e5927b06ce388161fa6ec08dc5ec74e4ab174c488af6ac60f39541d04b919\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/47/80/8eb21098e22c19d60b1c14021ee67442b4ad2d7991fdad46ba\n",
            "Successfully built onnx-simplifier\n",
            "Installing collected packages: onnx, onnxruntime, onnxoptimizer, onnx-simplifier\n",
            "Successfully installed onnx-1.10.1 onnx-simplifier-0.3.6 onnxoptimizer-0.2.6 onnxruntime-1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lln_dfQBRPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "08345296-760a-4e52-cdb2-fed2b3eb2190"
      },
      "source": [
        "dummy_input = torch.randn(1, 2, 8, 8)\n",
        "torch.onnx.export(Model(), dummy_input, 'model.onnx', opset_version=11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-45614e92db93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3vyE4ULC8t2"
      },
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0EvRu0mCXjq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "fb63ac7e-6f6e-4a75-87bf-d5e7d165b13b"
      },
      "source": [
        "model = onnx.load('model.onnx')\n",
        "modeli8 = onnx.load('modeli8.onnx')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-0c5b01ee3732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodeli8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modeli8.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time _=[model(x) for x in dummy_input]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time _=[model_i8(x) for x in dummy_input]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onnx/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(f, format, load_external_data)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mLoaded\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mModelProto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     '''\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onnx/__init__.py\u001b[0m in \u001b[0;36m_load_bytes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.onnx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32fzu7xyDEuE"
      },
      "source": [
        "onnx.checker.check_model(model)\n",
        "onnx.checker.check_model(modeli8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDOvrBsRDMkk"
      },
      "source": [
        "ort_session = onnxruntime.InferenceSession('model.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8MKb2JyDa4O"
      },
      "source": [
        "ort_sessioni8 = onnxruntime.InferenceSession('modeli8.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHP3VugoI_4H"
      },
      "source": [
        "import timm\n",
        "class EfficientNet(torch.nn.Module):\n",
        "    def __init__(self, backbone='mixnet_s', features=256, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.dropout = dropout\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone, num_classes=self.features, in_chans=2, exportable=True\n",
        "        )\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(self.features)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(self.dropout, inplace=True)\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.dropout(self.relu(self.bn(x)))\n",
        "        policy = self.fc3(x)\n",
        "        value = self.fc4(x)\n",
        "        return self.softmax(policy), self.tanh(value)\n",
        "        \n",
        "dummy_input = torch.randn(1, 2, 8, 8)\n",
        "_ = EfficientNet().eval()(dummy_input)\n",
        "torch.onnx.export(Model(), dummy_input, 'efficientnet.onnx', opset_version=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-uUr2FWT4hQ",
        "outputId": "d81706fa-f2af-40cc-f063-0242273f0bdc"
      },
      "source": [
        "model = Model().eval()\n",
        "model_i8 = torch.quantization.quantize_dynamic(model).eval()\n",
        "dummy_input = [torch.randn(1, 2, 8, 8) for _ in range(500)]\n",
        "%time _=[model(x) for x in dummy_input]\n",
        "%time _=[model_i8(x) for x in dummy_input]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 623 ms, sys: 8.79 ms, total: 632 ms\n",
            "Wall time: 633 ms\n",
            "CPU times: user 880 ms, sys: 49.2 ms, total: 929 ms\n",
            "Wall time: 931 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jrpwnPTCTL1"
      },
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType, quantize_qat\n",
        "model_input = \"efficientnet.onnx\"\n",
        "model_output = \"efficientnet_i8.onnx\"\n",
        "quantize_dynamic(model_input, model_output, weight_type=QuantType.QUInt8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jegxh6iSRD-C",
        "outputId": "37bdfccc-71f8-40b7-806c-38ff31da22ca"
      },
      "source": [
        "!python -m onnxsim efficientnet.onnx efficientnet_opt.onnx\n",
        "!python -m onnxsim efficientnet_i8.onnx efficientnet_i8_opt.onnx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplifying...\n",
            "Checking 0/3...\n",
            "Checking 1/3...\n",
            "Checking 2/3...\n",
            "Ok!\n",
            "Simplifying...\n",
            "Checking 0/3...\n",
            "Checking 1/3...\n",
            "Checking 2/3...\n",
            "Ok!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-aEWUR0N8Xu"
      },
      "source": [
        "model_input = \"efficientnet_opt.onnx\"\n",
        "model_output = \"efficientnet_opt_i8.onnx\"\n",
        "quantize_dynamic(model_input, model_output, weight_type=QuantType.QUInt8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ZBirupFkIs",
        "outputId": "6e1b2e1a-be2a-40c8-e018-163893c331a6"
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 15M\n",
            "-rw-r--r-- 1 root root 791K Sep 18 14:27 efficientnet_i8.onnx\n",
            "-rw-r--r-- 1 root root 787K Sep 18 14:27 efficientnet_i8_opt.onnx\n",
            "-rw-r--r-- 1 root root 3.1M Sep 18 14:26 efficientnet.onnx\n",
            "-rw-r--r-- 1 root root 785K Sep 18 14:27 efficientnet_opt_i8.onnx\n",
            "-rw-r--r-- 1 root root 3.1M Sep 18 14:27 efficientnet_opt.onnx\n",
            "-rw-r--r-- 1 root root 3.1M Sep 18 14:27 efficientnet-opt.onnx\n",
            "-rw-r--r-- 1 root root 3.1M Sep 18 14:27 efficientnet_opt-opt.onnx\n",
            "drwxr-xr-x 1 root root 4.0K Sep 16 13:40 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUhv-wBOKOhR",
        "outputId": "d7733a5a-774b-49c8-dce7-a5a7b2defbc2"
      },
      "source": [
        "ort_session = onnxruntime.InferenceSession('efficientnet.onnx')\n",
        "ort_session_opt = onnxruntime.InferenceSession('efficientnet_opt.onnx')\n",
        "ort_session_i8 = onnxruntime.InferenceSession('efficientnet_i8.onnx')\n",
        "# ort_session_opt_i = onnxruntime.InferenceSession('efficientnet_opt_i8.onnx')\n",
        "ort_session_i8_opt = onnxruntime.InferenceSession('efficientnet_i8_opt.onnx')\n",
        "dummy_input = [torch.randn(1, 2, 8, 8).numpy().astype(np.float32) for _ in range(500)]\n",
        "%time _=[ort_session.run(None, {'input.1': x}) for x in dummy_input]\n",
        "%time _=[ort_session_opt.run(None, {'input.1': x}) for x in dummy_input]\n",
        "%time _=[ort_session_i8.run(None, {'input.1': x}) for x in dummy_input]\n",
        "# %time _=[ort_session_opt_i8.run(None, {'input.1': x}) for x in dummy_input]\n",
        "%time _=[ort_session_i8_opt.run(None, {'input.1': x}) for x in dummy_input]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 167 ms, sys: 0 ns, total: 167 ms\n",
            "Wall time: 168 ms\n",
            "CPU times: user 164 ms, sys: 0 ns, total: 164 ms\n",
            "Wall time: 163 ms\n",
            "CPU times: user 238 ms, sys: 0 ns, total: 238 ms\n",
            "Wall time: 239 ms\n",
            "CPU times: user 233 ms, sys: 0 ns, total: 233 ms\n",
            "Wall time: 234 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90OTolgZKxQ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}